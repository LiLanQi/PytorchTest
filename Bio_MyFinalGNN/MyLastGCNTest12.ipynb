{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b61369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from tensorboardX import SummaryWriter\n",
    "# import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "from MyLastGCNTestmeth12 import MyValModel\n",
    "from MyLastGCN12 import MyNewGCN\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b179797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ed1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='Finetune')\n",
    "parser.add_argument('--batchsize', type=int, default=4)\n",
    "parser.add_argument('--result_src_NMF', type=str, default='../data/newNMF/NMF-LJ.xvg')\n",
    "parser.add_argument('--data_src_NMF', type=str, default='../data/newNMF/NMF_pdb')\n",
    "parser.add_argument('--result_src_ACE', type=str, default='../data/newACE/ACE-LJ.xvg')\n",
    "parser.add_argument('--data_src_ACE', type=str, default='../data/newACE/ACE_pdb')\n",
    "parser.add_argument('--result_src_wat', type=str, default='../data/newWater/water-LJ.xvg')\n",
    "parser.add_argument('--data_src_wat', type=str, default='../data/newWater/WAT_pdb')\n",
    "parser.add_argument('--result_src_meth', type=str, default='../data/newMeth/meth-LJ.xvg')\n",
    "parser.add_argument('--data_src_meth', type=str, default='../data/newMeth/meth_pdb')\n",
    "parser.add_argument('--lr', type=float, default=1E-2)\n",
    "# parser.add_argument('--momentum', type=float, default=0.9)\n",
    "\n",
    "parser.add_argument('--epoch', type=int, default=1000)\n",
    "parser.add_argument('--dropout', type=float, default=0)\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
    "\n",
    "\n",
    "dict_solute = {}\n",
    "dict_solvent_ACE = {}\n",
    "dict_solvent_NMF = {}\n",
    "dict_solvent_wat = {}\n",
    "dict_solvent_meth = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5182c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:1')\n",
    "args = parser.parse_args(args=[])\n",
    "writer = SummaryWriter('MyLastGCNTest12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614d6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    mx = mx.numpy()\n",
    "    rowsum = np.array(mx.sum(1))  # 对每一个特征进行归一化\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = np.diag(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    mx = torch.from_numpy(mx)\n",
    "    return mx\n",
    "\n",
    "\n",
    "def get_solute_position(rootdir):\n",
    "    label_index = [1]\n",
    "    path_list = readFileData(rootdir, label_index, \"ACE\")\n",
    "    for path in path_list:\n",
    "        file = open(path, \"r\")\n",
    "        file_list = file.readlines()\n",
    "        for i in range(5, 173 + 5):\n",
    "            temp_data = file_list[i].strip().split('1.00  0.00')[0][26:].strip()\n",
    "            temp_data = temp_data.split('.')\n",
    "            temp_atom = file_list[i][13:16].strip()  # 该点所对应的原子\n",
    "            dict_solute[temp_atom] = i - 5\n",
    "        break\n",
    "    return dict_solute\n",
    "\n",
    "\n",
    "def get_solvent_position(rootdir, solvent):\n",
    "    dict_solvent = {}\n",
    "    if (solvent == \"ACE\"):\n",
    "        botom_index = 8\n",
    "    elif (solvent == \"NMF\"):\n",
    "        botom_index = 11\n",
    "    elif (solvent == \"wat\"):\n",
    "        botom_index = 5\n",
    "    elif (solvent == \"meth\"):\n",
    "        botom_index = 17\n",
    "    label_index = [1]\n",
    "    path_list = readFileData(rootdir, label_index, solvent)\n",
    "    for path in path_list:\n",
    "        file = open(path, \"r\")\n",
    "        file_list = file.readlines()\n",
    "        left = len(file_list) - botom_index\n",
    "        right = len(file_list) - 2\n",
    "        for i in range(left, right):\n",
    "            temp_data = file_list[i].strip().split('1.00  0.00')[0][26:].strip()\n",
    "            temp_data = temp_data.split('.')\n",
    "            temp_atom = file_list[i][13:16].strip()  # 该点所对应的原子\n",
    "            dict_solvent[temp_atom] = i - left\n",
    "        break\n",
    "    return dict_solvent\n",
    "\n",
    "\n",
    "# 返回一个结果张量\n",
    "def readFileResult(root_dir):\n",
    "    file = open(root_dir, \"r\")\n",
    "    file_list = file.readlines()\n",
    "    result_list = []\n",
    "    for i in range(0, 100000):\n",
    "        temp_data = file_list[i].strip().split('  ')[-1].strip()\n",
    "        temp_data = float(temp_data)\n",
    "        result_list.append(temp_data)\n",
    "    result = torch.tensor(result_list)\n",
    "    return result\n",
    "\n",
    "# def read_Speed(path):\n",
    "#     return np.load(path, allow_pickle=True).item()\n",
    "\n",
    "total_labels_ACE = readFileResult(args.result_src_ACE)\n",
    "total_labels_NMF = readFileResult(args.result_src_NMF)\n",
    "total_labels_wat = readFileResult(args.result_src_wat)\n",
    "total_labels_meth = readFileResult(args.result_src_meth)\n",
    "\n",
    "# total_labels_speed_ACE = read_Speed(\"./solute_solvent_speed_list_ACE_for_all_system.npy\")\n",
    "# total_labels_speed_NMF = read_Speed(\"./solute_solvent_speed_list_NMF_for_all_system.npy\")\n",
    "# total_labels_speed_wat = read_Speed(\"./solute_solvent_speed_list_wat_for_all_system.npy\")\n",
    "# total_labels_speed_meth = read_Speed(\"./solute_solvent_speed_list_meth_for_all_system.npy\")\n",
    "\n",
    "\n",
    "def readFileData(root_dir, lable_index, solvent):\n",
    "    path_list = []\n",
    "    for i in range(len(lable_index)):\n",
    "        j = lable_index[i]\n",
    "        temp_path = solvent + str(j) + \".pdb\"\n",
    "        path = os.path.join(root_dir, temp_path)\n",
    "        path_list.append(path)\n",
    "    # path_list.append(os.path.join(root_dir,\"md/origin.pdb\")) 暂时不需要\n",
    "    return path_list\n",
    "\n",
    "\n",
    "def get_solute_adj():\n",
    "    solute_adj = []\n",
    "    bonds = 'S1-O3', 'S1-O4', 'S1-F1', 'S1-O1', 'O1-C3', 'C3-C4', 'C4-H3', 'C4-C5', 'C5-H4', 'C5-C6', 'C6-C1', 'C1-H1', 'C1-C2', 'C2-H2', 'C2-C3', 'C6-C19', 'C19-C14', 'C14-C13', 'C13-H9', 'C13-C18', 'C18-H12', 'C18-C17', 'C17-C16', 'C16-H11', 'C16-C15', 'C15-H10', 'C15-C14', 'C17-O2', 'O2-S2', 'S2-O5', 'S2-O6', 'S2-F2', 'C19-H13', 'C19-C10', 'C10-C11', 'C11-H7', 'C11-C12', 'C12-H8', 'C12-C7', 'C7-C8', 'C8-H5', 'C8-C9', 'C9-H6', 'C9-C10', 'C7-O25', 'O25-S8', 'S8-O26', 'S8-O27', 'S8-O22', 'O22-C64', 'C64-C69', 'C69-H47', 'C69-C68', 'C68-H46', 'C68-C67', 'C67-C66', 'C66-H45', 'C66-C65', 'C65-H44', 'C65-C64', 'C67-C76', 'C76-H52', 'C76-C71', 'C71-C70', 'C70-H48', 'C70-C75', 'C75-H51', 'C75-C74', 'C74-C73', 'C73-H50', 'C73-C72', 'C72-H49', 'C72-C71', 'C74-O24', 'O24-S9', 'S9-O29', 'S9-O30', 'S9-O28', 'O28-C26', 'C26-C27', 'C27-H18', 'C27-C28', 'C28-H19', 'C28-C29', 'C29-C30', 'C30-H20', 'C30-C31', 'C31-H21', 'C31-C26', 'C29-C38', 'C38-H26', 'C38-C25', 'C25-C20', 'C20-H14', 'C20-C21', 'C21-H15', 'C21-C22', 'C22-C23', 'C23-H16', 'C23-C24', 'C24-H17', 'C24-C25', 'C22-O7', 'O7-S3', 'S3-O9', 'S3-O10', 'S3-F3', 'C38-C33', 'C33-C32', 'C32-H22', 'C32-C37', 'C37-H25', 'C37-C36', 'C36-C35', 'C35-H24', 'C35-C34', 'C34-H23', 'C34-C33', 'C36-O8', 'O8-S4', 'S4-O11', 'S4-O12', 'S4-F4', 'C76-C63', 'C63-C62', 'C62-H43', 'C62-C61', 'C61-H42', 'C61-C60', 'C60-C59', 'C59-H41', 'C59-C58', 'C58-H40', 'C58-C63', 'C60-O23', 'O23-S7', 'S7-O20', 'S7-O21', 'S7-O17', 'O17-C55', 'C55-C56', 'C56-H38', 'C56-C51', 'C51-H35', 'C51-C52', 'C52-C53', 'C53-H36', 'C53-C54', 'C54-C55', 'C54-H37', 'C52-C57', 'C57-H39', 'C57-C48', 'C48-C47', 'C47-H32', 'C47-C46', 'C46-H31', 'C46-C45', 'C45-C50', 'C50-H34', 'C50-C49', 'C49-H33', 'C49-C48', 'C45-O13', 'O13-S5', 'S5-O14', 'S5-O15', 'S5-F5', 'C57-C44', 'C44-C43', 'C43-H30', 'C43-C42', 'C42-H29', 'C42-C41', 'C41-C40', 'C40-H28', 'C40-C39', 'C39-H27', 'C39-C44', 'C41-O16', 'O16-S6', 'S6-O18', 'S6-O19', 'S6-F6'\n",
    "    for connect_atom in bonds:\n",
    "        left_atom = connect_atom.split(\"-\")[0]\n",
    "        right_atom = connect_atom.split(\"-\")[-1]\n",
    "        for i in range(12):\n",
    "            left_atom_value = dict_solute[left_atom] + 173 * i\n",
    "            right_atom_value = dict_solute[right_atom] + 173 * i\n",
    "            solute_adj.append((left_atom_value, right_atom_value))\n",
    "            solute_adj.append((right_atom_value, left_atom_value))\n",
    "    return solute_adj\n",
    "\n",
    "\n",
    "def get_solvent_adj(solvent, dim):\n",
    "    if (solvent == \"ACE\"):\n",
    "        atom_nums = 6\n",
    "        atom_g = 1490\n",
    "        bonds = 'C1-H1', 'C1-H2', 'C1-H3', 'C1-C2', 'C2-N1'\n",
    "        dict_solvent = dict_solvent_ACE\n",
    "    elif (solvent == \"NMF\"):\n",
    "        atom_nums = 9\n",
    "        atom_g = 1350\n",
    "        bonds = 'C1-O1', 'C1-H1', 'C1-N1', 'N1-H2', 'C2-N1', 'C2-H3', 'C2-H4', 'C2-H5'\n",
    "        dict_solvent = dict_solvent_NMF\n",
    "    elif (solvent == \"wat\"):\n",
    "        atom_nums = 3\n",
    "        atom_g = 4928\n",
    "        bonds = 'O-H1', 'O-H2'\n",
    "        dict_solvent = dict_solvent_wat\n",
    "    elif (solvent == \"meth\"):\n",
    "        atom_nums = 15\n",
    "        atom_g = 1089\n",
    "        bonds = 'C7-H6', 'C7-H7', 'C7-H8', 'C7-C2', 'C2-C1', 'C1-H1', 'C1-C6', 'C6-H5', 'C6-C5', 'C5-H4', 'C5-C4', 'C4-H3', 'C4-C3', 'C3-H2', 'C3-C2'\n",
    "        dict_solvent = dict_solvent_meth\n",
    "    solvent_adj = []\n",
    "    for connect_atom in bonds:\n",
    "        left_atom = connect_atom.split(\"-\")[0]\n",
    "        right_atom = connect_atom.split(\"-\")[-1]\n",
    "        for i in range(atom_g):\n",
    "            left_atom_value = dict_solvent[left_atom] + atom_nums * i\n",
    "            right_atom_value = dict_solvent[right_atom] + atom_nums * i\n",
    "            solvent_adj.append((left_atom_value, right_atom_value))\n",
    "            solvent_adj.append((right_atom_value, left_atom_value))\n",
    "    # A_loop = torch.eye(atom_nums * atom_g, atom_nums * atom_g)\n",
    "    # solvent_adj = solvent_adj + A_loop\n",
    "    return solvent_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ab12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_trainset(Dataset):\n",
    "\n",
    "    def __init__(self, phase, lable_index, rootdir_meth):\n",
    "        path_list_meth = readFileData(rootdir_meth, lable_index, \"meth\")  # 得到对应methx.pdb文件的list\n",
    "        # count0= 4566 countN= 3486 countC= 13194 countF= 216 countS= 324 countH= 26274\n",
    "        self.solute_list_meth, self.solvent_list_meth, self.lables_list_meth = self.__read_data__(path_list_meth, lable_index, \"meth\")\n",
    "\n",
    "    def __read_data__(self, path_list, lable_index, solvent):\n",
    "        solute_list = []\n",
    "        solvent_list = []\n",
    "        lables_list = []\n",
    "        atom_to_feature = []\n",
    "        total_labels = []\n",
    "        if(solvent == \"ACE\"):\n",
    "            atom_to_feature = ACE_atom_to_feature\n",
    "            total_labels = total_labels_ACE\n",
    "            # solute_speed_list = solute_speed_list_ACE\n",
    "            # solvent_speed_list = solvent_speed_list_ACE\n",
    "            # total_labels_speed = total_labels_speed_ACE\n",
    "        elif (solvent == \"NMF\"):\n",
    "            atom_to_feature = NMF_atom_to_feature\n",
    "            total_labels = total_labels_NMF\n",
    "            # solute_speed_list = solute_speed_list_NMF\n",
    "            # solvent_speed_list = solvent_speed_list_NMF\n",
    "            # total_labels_speed = total_labels_speed_NMF\n",
    "        elif (solvent == \"wat\"):\n",
    "            atom_to_feature = wat_atom_to_feature\n",
    "            total_labels = total_labels_wat\n",
    "            # solute_speed_list = solute_speed_list_wat\n",
    "            # solvent_speed_list = solvent_speed_list_wat\n",
    "            # total_labels_speed = total_labels_speed_wat\n",
    "        elif (solvent == \"meth\"):\n",
    "            atom_to_feature = meth_atom_to_feature\n",
    "            total_labels = total_labels_meth\n",
    "            # solute_speed_list = solute_speed_list_meth\n",
    "            # solvent_speed_list = solvent_speed_list_meth\n",
    "            # total_labels_speed = total_labels_speed_meth\n",
    "        # 对所有的ACE.pdb文件里的数据进行预处理\n",
    "        current_data = -1\n",
    "        for path in path_list:\n",
    "            current_data = current_data + 1\n",
    "            if (current_data % 100 == 9):\n",
    "                print(\"path=\", path, \"current_data=\", current_data, \",all_data=\", len(path_list), \"\")\n",
    "            file = open(path, \"r\")\n",
    "            file_list = file.readlines()\n",
    "            temp_result_list = []\n",
    "            position_list = []\n",
    "            bottom = len(file_list) - 2\n",
    "            for i in range(5, 2081):\n",
    "                temp_data = file_list[i].strip().split('1.00  0.00')[0][26:].strip()\n",
    "                temp_data = temp_data.split('.')\n",
    "                temp_atom = file_list[i][13:16].strip()  # 该点所对应的原子\n",
    "                # single_temp_atom = file_list[i][13]\n",
    "                x = float(temp_data[0] + \".\" + temp_data[1][0:3])\n",
    "                y = float(temp_data[1][3:].strip() + \".\" + temp_data[2][0:3])\n",
    "                z = float(temp_data[2][3:].strip() + \".\" + temp_data[3][0:3])\n",
    "                # print(\"solute_addtional_feature[temp_atom]=\",solute_addtional_feature[temp_atom].shape)\n",
    "                temp_result_list.append(solute_addtional_feature[temp_atom])\n",
    "                position_list.append(x)\n",
    "                position_list.append(y)\n",
    "                position_list.append(z)\n",
    "            for i in range(2081, bottom):\n",
    "                temp_data = file_list[i].strip().split('1.00  0.00')[0][26:].strip()\n",
    "                temp_data = temp_data.split('.')\n",
    "                temp_atom = file_list[i][13:16].strip()  # 该点所对应的原子\n",
    "                # single_temp_atom = file_list[i][13]\n",
    "                x = float(temp_data[0] + \".\" + temp_data[1][0:3])\n",
    "                y = float(temp_data[1][3:].strip() + \".\" + temp_data[2][0:3])\n",
    "                z = float(temp_data[2][3:].strip() + \".\" + temp_data[3][0:3])\n",
    "                # print(\"solute_addtional_feature[temp_atom]=\",solute_addtional_feature[temp_atom].shape)\n",
    "                temp_result_list.append(atom_to_feature[temp_atom])\n",
    "                position_list.append(x)\n",
    "                position_list.append(y)\n",
    "                position_list.append(z)\n",
    "\n",
    "            temp = torch.stack(temp_result_list)\n",
    "            position_tensor = torch.tensor(position_list).reshape(-1, 3)\n",
    "            # solute_speed = solute_speed_list[lable_index[current_data]]  # solute_speed_feature\n",
    "            # solute_speed = solute_speed.reshape(-1, 1)\n",
    "            # solvent_speed = solvent_speed_list[lable_index[current_data]]  # solvent_speed_feature\n",
    "            # solvent_speed = solvent_speed.reshape(-1, 1)\n",
    "            # speed = torch.cat((solute_speed, solvent_speed), 0)\n",
    "            temp = torch.cat((temp, position_tensor), 1)\n",
    "            # temp = torch.cat((temp, speed), 1)\n",
    "            solute_data = temp[:173 * 12, :]\n",
    "            solvent_data = temp[173 * 12:, :]\n",
    "            solute_list.append(solute_data)  # 存入每个ACE文件的溶质图\n",
    "            solvent_list.append(solvent_data)  # 存入每个ACE文件的溶剂图\n",
    "        for i in range(len(lable_index)):\n",
    "            lables_list.append(total_labels[lable_index[i]])  # 存入每个ACE文件的标签\n",
    "        return solute_list, solvent_list, lables_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        solute_list_meth = self.solute_list_meth[index]\n",
    "        solvent_list_meth = self.solvent_list_meth[index]\n",
    "        lable_meth = self.lables_list_meth[index]\n",
    "\n",
    "        return solute_list_meth, solvent_list_meth, lable_meth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.solute_list_meth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c88ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainset(Dataset):\n",
    "\n",
    "    def __init__(self, rootdir_ACE, phase, rootdir_NMF,  lable_index, rootdir_wat):\n",
    "        self.root = rootdir_ACE\n",
    "        path_list_ACE = readFileData(rootdir_ACE, lable_index, \"ACE\")  # 得到对应ACEx.pdb文件的list\n",
    "        path_list_NMF = readFileData(rootdir_NMF, lable_index, \"NMF\")  # 得到对应NMFx.pdb文件的list\n",
    "        path_list_wat = readFileData(rootdir_wat, lable_index, \"wat\")  # 得到对应methx.pdb文件的list\n",
    "        # count0= 4566 countN= 3486 countC= 13194 countF= 216 countS= 324 countH= 26274\n",
    "\n",
    "        self.solute_list_ACE, self.solvent_list_ACE, self.lables_list_ACE = self.__read_data__(path_list_ACE, lable_index, \"ACE\")\n",
    "        self.solute_list_NMF, self.solvent_list_NMF, self.lables_list_NMF = self.__read_data__(path_list_NMF, lable_index, \"NMF\")\n",
    "        self.solute_list_wat, self.solvent_list_wat, self.lables_list_wat = self.__read_data__(path_list_wat, lable_index, \"wat\")\n",
    "\n",
    "    def __read_data__(self, path_list, lable_index, solvent):\n",
    "        solute_list = []\n",
    "        solvent_list = []\n",
    "        lables_list = []\n",
    "        atom_to_feature = []\n",
    "        total_labels = []\n",
    "        if(solvent == \"ACE\"):\n",
    "            atom_to_feature = ACE_atom_to_feature\n",
    "            total_labels = total_labels_ACE\n",
    "            # solute_speed_list = solute_speed_list_ACE\n",
    "            # solvent_speed_list = solvent_speed_list_ACE\n",
    "            # total_labels_speed = total_labels_speed_ACE\n",
    "        elif (solvent == \"NMF\"):\n",
    "            atom_to_feature = NMF_atom_to_feature\n",
    "            total_labels = total_labels_NMF\n",
    "            # solute_speed_list = solute_speed_list_NMF\n",
    "            # solvent_speed_list = solvent_speed_list_NMF\n",
    "            # total_labels_speed = total_labels_speed_NMF\n",
    "        elif (solvent == \"wat\"):\n",
    "            atom_to_feature = wat_atom_to_feature\n",
    "            total_labels = total_labels_wat\n",
    "            # solute_speed_list = solute_speed_list_wat\n",
    "            # solvent_speed_list = solvent_speed_list_wat\n",
    "            # total_labels_speed = total_labels_speed_wat\n",
    "        elif (solvent == \"meth\"):\n",
    "            atom_to_feature = meth_atom_to_feature\n",
    "            total_labels = total_labels_meth\n",
    "            # solute_speed_list = solute_speed_list_meth\n",
    "            # solvent_speed_list = solvent_speed_list_meth\n",
    "            # total_labels_speed = total_labels_speed_meth\n",
    "        # 对所有的ACE.pdb文件里的数据进行预处理\n",
    "        current_data = -1\n",
    "        for path in path_list:\n",
    "            current_data = current_data + 1\n",
    "            if (current_data % 1000 == 9):\n",
    "                print(\"path=\", path, \"current_data=\", current_data, \",all_data=\", len(path_list), \"\")\n",
    "            file = open(path, \"r\")\n",
    "            file_list = file.readlines()\n",
    "            temp_result_list = []\n",
    "            position_list = []\n",
    "            bottom = len(file_list) - 2\n",
    "            for i in range(5, 2081):\n",
    "                temp_data = file_list[i].strip().split('1.00  0.00')[0][26:].strip()\n",
    "                temp_data = temp_data.split('.')\n",
    "                temp_atom = file_list[i][13:16].strip()  # 该点所对应的原子\n",
    "                # single_temp_atom = file_list[i][13]\n",
    "                x = float(temp_data[0] + \".\" + temp_data[1][0:3])\n",
    "                y = float(temp_data[1][3:].strip() + \".\" + temp_data[2][0:3])\n",
    "                z = float(temp_data[2][3:].strip() + \".\" + temp_data[3][0:3])\n",
    "                # print(\"solute_addtional_feature[temp_atom]=\",solute_addtional_feature[temp_atom].shape)\n",
    "                temp_result_list.append(solute_addtional_feature[temp_atom]) #溶质feature\n",
    "                position_list.append(x)\n",
    "                position_list.append(y)\n",
    "                position_list.append(z)\n",
    "            for i in range(2081, bottom):\n",
    "                temp_data = file_list[i].strip().split('1.00  0.00')[0][26:].strip()\n",
    "                temp_data = temp_data.split('.')\n",
    "                temp_atom = file_list[i][13:16].strip()  # 该点所对应的原子\n",
    "                # single_temp_atom = file_list[i][13]\n",
    "                x = float(temp_data[0] + \".\" + temp_data[1][0:3])\n",
    "                y = float(temp_data[1][3:].strip() + \".\" + temp_data[2][0:3])\n",
    "                z = float(temp_data[2][3:].strip() + \".\" + temp_data[3][0:3])\n",
    "                # print(\"solute_addtional_feature[temp_atom]=\",solute_addtional_feature[temp_atom].shape)\n",
    "                temp_result_list.append(atom_to_feature[temp_atom])   #溶剂feature\n",
    "                position_list.append(x)\n",
    "                position_list.append(y)\n",
    "                position_list.append(z)\n",
    "\n",
    "            temp = torch.stack(temp_result_list)\n",
    "            position_tensor = torch.tensor(position_list).reshape(-1, 3)\n",
    "            # solute_speed = solute_speed_list[lable_index[current_data]] #solute_speed_feature\n",
    "            # solute_speed = solute_speed.reshape(-1, 1)\n",
    "            # solvent_speed = solvent_speed_list[lable_index[current_data]] #solvent_speed_feature\n",
    "            # solvent_speed = solvent_speed.reshape(-1, 1)\n",
    "            # speed = torch.cat((solute_speed, solvent_speed), 0)\n",
    "            temp = torch.cat((temp, position_tensor), 1)\n",
    "            # temp = torch.cat((temp, speed), 1)\n",
    "            solute_data = temp[:173 * 12, :]\n",
    "            solvent_data = temp[173 * 12:, :]\n",
    "            solute_list.append(solute_data)  # 存入每个ACE文件的溶质图\n",
    "            solvent_list.append(solvent_data)  # 存入每个ACE文件的溶剂图\n",
    "        for i in range(len(lable_index)):\n",
    "            lables_list.append(total_labels[lable_index[i]])  # 存入每个ACE文件的标签\n",
    "        return solute_list, solvent_list, lables_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        solute_list_ACE = self.solute_list_ACE[index]\n",
    "        solvent_list_ACE = self.solvent_list_ACE[index]\n",
    "        # print(\"self.lables_list_ACE[index]=\", self.lables_list_ACE[index])\n",
    "        lable_ACE = self.lables_list_ACE[index]\n",
    "\n",
    "        solute_list_NMF = self.solute_list_NMF[index]\n",
    "        solvent_list_NMF = self.solvent_list_NMF[index]\n",
    "        lable_NMF = self.lables_list_NMF[index]\n",
    "\n",
    "        solute_list_wat = self.solute_list_wat[index]\n",
    "        solvent_list_wat = self.solvent_list_wat[index]\n",
    "        lable_wat = self.lables_list_wat[index]\n",
    "\n",
    "        return solute_list_ACE, solvent_list_ACE, lable_ACE, solute_list_NMF, solvent_list_NMF, lable_NMF, solute_list_wat, solvent_list_wat, lable_wat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.solute_list_ACE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126b1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root_path_ACE, batch_size, phase, root_path_NMF, label_index,root_path_wat):\n",
    "    data = trainset(root_path_ACE, phase, root_path_NMF,label_index, root_path_wat)\n",
    "    print(\"data=\", data)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=12)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2afbed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(batch_size, phase, label_index, root_path_meth):\n",
    "    data = test_trainset(phase, label_index, root_path_meth)\n",
    "    print(\"data=\", data)\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=12)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f9f9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(net, val_loader, solute_adj, solvent_adj_ACE, solvent_adj_NMF, solvent_adj_wat, current_epoch):\n",
    "    net.eval()\n",
    "    SUMACE1 = 0\n",
    "    SUMACE2 = 0\n",
    "    SUMACE3 = 0\n",
    "    SUMACE4 = 0\n",
    "    SUMACE5 = 0\n",
    "\n",
    "    SUMNMF1 = 0\n",
    "    SUMNMF2 = 0\n",
    "    SUMNMF3 = 0\n",
    "    SUMNMF4 = 0\n",
    "    SUMNMF5 = 0\n",
    "\n",
    "    SUMwat1 = 0\n",
    "    SUMwat2 = 0\n",
    "    SUMwat3 = 0\n",
    "    SUMwat4 = 0\n",
    "    SUMwat5 = 0\n",
    "    for i_batch, batch_data in tqdm(enumerate(val_loader)):\n",
    "        solute_data_ACE, solvent_data_ACE, labels_ACE, solute_data_NMF, solvent_data_NMF, labels_NMF, solute_data_wat, solvent_data_wat, labels_wat = batch_data\n",
    "        labels_ACE = labels_ACE.to(DEVICE)\n",
    "        labels_NMF = labels_NMF.to(DEVICE)\n",
    "        labels_wat = labels_wat.to(DEVICE)\n",
    "        labels = torch.cat((labels_ACE, labels_NMF), 0)\n",
    "        labels = torch.cat((labels, labels_wat), 0)\n",
    "        solute_data_ACE = solute_data_ACE.to(DEVICE)\n",
    "        solute_data_NMF = solute_data_NMF.to(DEVICE)\n",
    "        solute_data_wat = solute_data_wat.to(DEVICE)\n",
    "        solvent_data_ACE = solvent_data_ACE.to(DEVICE)\n",
    "        solvent_data_NMF = solvent_data_NMF.to(DEVICE)\n",
    "        solvent_data_wat = solvent_data_wat.to(DEVICE)\n",
    "        solute_adj = solute_adj.to(DEVICE)\n",
    "        solvent_adj_ACE = solvent_adj_ACE.to(DEVICE)\n",
    "        solvent_adj_NMF = solvent_adj_NMF.to(DEVICE)\n",
    "        solvent_adj_wat = solvent_adj_wat.to(DEVICE)\n",
    "        with torch.set_grad_enabled(False):  # 当requires_grad设置为False时,反向传播时就不会自动求导了，因此大大节约了显存或者说内存。\n",
    "            outputs = net(solute_data_ACE, solvent_data_ACE, solute_adj, solvent_adj_ACE, solute_data_NMF,\n",
    "                          solvent_data_NMF, solvent_adj_NMF, solute_data_wat, solvent_data_wat, solvent_adj_wat,smile).squeeze(-1)\n",
    "        deviation = abs((outputs - labels) / labels)\n",
    "        print(\"outputs=\", outputs)\n",
    "        print(\"labels=\", labels)\n",
    "        print(\"deviation=\", deviation)\n",
    "        for i in range(deviation.shape[0]):\n",
    "            if (i < args.batchsize):\n",
    "                if (deviation[i] < 0.01):\n",
    "                    SUMACE1 = SUMACE1 + 1\n",
    "                if (deviation[i] < 0.02):\n",
    "                    SUMACE2 = SUMACE2 + 1\n",
    "                if (deviation[i] < 0.03):\n",
    "                    SUMACE3 = SUMACE3 + 1\n",
    "                if (deviation[i] < 0.04):\n",
    "                    SUMACE4 = SUMACE4 + 1\n",
    "                if (deviation[i] < 0.05):\n",
    "                    SUMACE5 = SUMACE5 + 1\n",
    "            elif (i >= args.batchsize and i < 2*args.batchsize):\n",
    "                if (deviation[i] < 0.01):\n",
    "                    SUMNMF1 = SUMNMF1 + 1\n",
    "                if (deviation[i] < 0.02):\n",
    "                    SUMNMF2 = SUMNMF2 + 1\n",
    "                if (deviation[i] < 0.03):\n",
    "                    SUMNMF3 = SUMNMF3 + 1\n",
    "                if (deviation[i] < 0.04):\n",
    "                    SUMNMF4 = SUMNMF4 + 1\n",
    "                if (deviation[i] < 0.05):\n",
    "                    SUMNMF5 = SUMNMF5 + 1\n",
    "            elif (i >= 2*args.batchsize):\n",
    "                if (deviation[i] < 0.01):\n",
    "                    SUMwat1 = SUMwat1 + 1\n",
    "                if (deviation[i] < 0.02):\n",
    "                    SUMwat2 = SUMwat2 + 1\n",
    "                if (deviation[i] < 0.03):\n",
    "                    SUMwat3 = SUMwat3 + 1\n",
    "                if (deviation[i] < 0.04):\n",
    "                    SUMwat4 = SUMwat4 + 1\n",
    "                if (deviation[i] < 0.05):\n",
    "                    SUMwat5 = SUMwat5 + 1\n",
    "    # print(\"SUMACE1 = \", SUMACE1, \"SUMACE2 = \", SUMACE2, \"SUMACE3 = \", SUMACE3, \"SUMACE4 = \", SUMACE4, \"SUMACE5 = \",\n",
    "    #       SUMACE5)\n",
    "    # print(\"SUMNMF1 = \", SUMNMF1, \"SUMNMF2 = \", SUMNMF2, \"SUMNMF3 = \", SUMNMF3, \"SUMNMF4 = \", SUMNMF4, \"SUMNMF5 = \",\n",
    "    #       SUMNMF5)\n",
    "    # print(\"SUMwat1 = \", SUMwat1, \"SUMwat2 = \", SUMwat2, \"SUMwat3 = \", SUMwat3, \"SUMwat4 = \", SUMwat4,\n",
    "    #       \"SUMwat5 = \", SUMwat5)\n",
    "    ACE_accuracy = (SUMACE5) / (len(val_loader) * args.batchsize)\n",
    "    NMF_accuracy = (SUMNMF5) / (len(val_loader) * args.batchsize)\n",
    "    wat_accuracy = (SUMwat5) / (len(val_loader) * args.batchsize)\n",
    "\n",
    "    print(\"tatol\", (SUMACE5 * 100) / (len(val_loader) * args.batchsize), \"% ACE in 5%;\", \"tatol\",\n",
    "          (SUMNMF5 * 100) / (len(val_loader) * args.batchsize), \"% NMF in 5%;\", \"tatol\",\n",
    "          (SUMwat5 * 100) / (len(val_loader) * args.batchsize), \"% Water in 5%\")\n",
    "    return ACE_accuracy, NMF_accuracy, wat_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fbd8aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_model, test_loader, solute_adj, solvent_adj_meth, PATH1, bestSUMmeth5, bestSUMmeth10, best_PATH5, best_PATH10, current_epoch, ACE_accuracy, NMF_accuracy, wat_accuracy):\n",
    "    test_model.eval()\n",
    "    SUMmeth1 = 0\n",
    "    SUMmeth2 = 0\n",
    "    SUMmeth3 = 0\n",
    "    SUMmeth4 = 0\n",
    "    SUMmeth5 = 0\n",
    "    SUMmeth6 = 0\n",
    "    SUMmeth7 = 0\n",
    "    SUMmeth8 = 0\n",
    "    SUMmeth9 = 0\n",
    "    SUMmeth10 = 0\n",
    "\n",
    "    for i_batch, batch_data in tqdm(enumerate(test_loader)):\n",
    "        solute_data_meth, solvent_data_meth, labels_meth = batch_data\n",
    "        labels = labels_meth.to(DEVICE)\n",
    "        solute_data_meth = solute_data_meth.to(DEVICE)\n",
    "        solvent_data_meth = solvent_data_meth.to(DEVICE)\n",
    "        solute_adj = solute_adj.to(DEVICE)\n",
    "        solvent_adj_meth = solvent_adj_meth.to(DEVICE)\n",
    "        with torch.set_grad_enabled(False):  # 当requires_grad设置为False时,反向传播时就不会自动求导了，因此大大节约了显存或者说内存。\n",
    "            outputs = test_model(solute_adj, solute_data_meth, solvent_data_meth, solvent_adj_meth, smile).squeeze(-1)\n",
    "        deviation = abs((outputs - labels) / labels)\n",
    "        # if (i_batch % 100 == 9):\n",
    "        #     print(\"outputs=\", outputs)\n",
    "        #     print(\"labels=\", labels)\n",
    "        #     print(\"deviation=\", deviation)\n",
    "        for i in range(deviation.shape[0]):\n",
    "            if (i < args.batchsize):\n",
    "                if (deviation[i] < 0.01):\n",
    "                    SUMmeth1 = SUMmeth1 + 1\n",
    "                if (deviation[i] < 0.02):\n",
    "                    SUMmeth2 = SUMmeth2 + 1\n",
    "                if (deviation[i] < 0.03):\n",
    "                    SUMmeth3 = SUMmeth3 + 1\n",
    "                if (deviation[i] < 0.04):\n",
    "                    SUMmeth4 = SUMmeth4 + 1\n",
    "                if (deviation[i] < 0.05):\n",
    "                    SUMmeth5 = SUMmeth5 + 1\n",
    "                if (deviation[i] < 0.06):\n",
    "                    SUMmeth6 = SUMmeth6 + 1\n",
    "                if (deviation[i] < 0.07):\n",
    "                    SUMmeth7 = SUMmeth7 + 1\n",
    "                if (deviation[i] < 0.08):\n",
    "                    SUMmeth8 = SUMmeth8 + 1\n",
    "                if (deviation[i] < 0.09):\n",
    "                    SUMmeth9 = SUMmeth9 + 1\n",
    "                if (deviation[i] < 0.1):\n",
    "                    SUMmeth10 = SUMmeth10 + 1\n",
    "    if (SUMmeth10 > bestSUMmeth10):\n",
    "        bestSUMmeth10 = SUMmeth10\n",
    "        best_PATH10 = PATH1\n",
    "    if (SUMmeth5 > bestSUMmeth5):\n",
    "        bestSUMmeth5 = SUMmeth5\n",
    "        best_PATH5 = PATH1\n",
    "    # print(\"SUMmeth1 = \", SUMmeth1, \"SUMmeth2 = \", SUMmeth2, \"SUMmeth3 = \", SUMmeth3, \"SUMmeth4 = \", SUMmeth4,\n",
    "    #       \"SUMmeth5 = \", SUMmeth5)\n",
    "    # print(\"SUMmeth6 = \", SUMmeth6, \"SUMmeth7 = \", SUMmeth7, \"SUMmeth8 = \", SUMmeth8, \"SUMmeth9 = \", SUMmeth9,\n",
    "    #       \"SUMmeth10 = \", SUMmeth10)\n",
    "    meth_accuracy = (SUMmeth5) / (len(test_loader) * args.batchsize)\n",
    "    writer.add_scalars('Accuracy ',\n",
    "                       {\"ACE_acc\": ACE_accuracy, \"NMF_acc\": NMF_accuracy, \"wat_acc\": wat_accuracy,\n",
    "                        \"meth_acc\": meth_accuracy},\n",
    "                       current_epoch)\n",
    "    print(\"tatol\", (SUMmeth5*100)/(len(test_loader)*args.batchsize), \"% meth in 5%;\", \"tatol\", (SUMmeth10*100)/(len(test_loader)*args.batchsize), \"% meth in 10%\")\n",
    "    return best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10\n",
    "\n",
    "def build_model():\n",
    "    net = MyNewGCN(nfeat=9, nhid=64, nclass=128, dropout=args.dropout, DEVICE=DEVICE, batch_size=args.batchsize)\n",
    "    net = net.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "    test_model = MyValModel(nfeat=9, nhid=64, nclass=128, dropout=args.dropout, DEVICE=DEVICE, batch_size=args.batchsize)\n",
    "    test_model = test_model.to(DEVICE)\n",
    "    return net, optimizer, criterion, test_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b71fb2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, criterion, test_model,train_loader, solute_adj, solvent_adj_ACE, solvent_adj_NMF, solvent_adj_wat, val_loader, solvent_adj_meth, test_loader,best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10, current_epoch):\n",
    "\n",
    "    loss_list = []\n",
    "    for epoch in range(args.epoch):\n",
    "        # tf_flag = 0\n",
    "        net.train()\n",
    "        total_loss = 0\n",
    "        running_loss = 0\n",
    "        for i_batch, batch_data in tqdm(enumerate(train_loader)):\n",
    "            solute_data_ACE, solvent_data_ACE, labels_ACE, solute_data_NMF, solvent_data_NMF, labels_NMF, solute_data_wat, solvent_data_wat, labels_wat = batch_data\n",
    "            labels_ACE = labels_ACE.to(DEVICE)\n",
    "            labels_NMF = labels_NMF.to(DEVICE)\n",
    "            labels_wat = labels_wat.to(DEVICE)\n",
    "            labels = torch.cat((labels_ACE, labels_NMF), 0)\n",
    "            labels = torch.cat((labels, labels_wat), 0)\n",
    "            solute_data_ACE = solute_data_ACE.to(DEVICE)\n",
    "            solute_data_NMF = solute_data_NMF.to(DEVICE)\n",
    "            solute_data_wat = solute_data_wat.to(DEVICE)\n",
    "            solvent_data_ACE = solvent_data_ACE.to(DEVICE)\n",
    "            solvent_data_NMF = solvent_data_NMF.to(DEVICE)\n",
    "            solvent_data_wat = solvent_data_wat.to(DEVICE)\n",
    "            solute_adj = solute_adj.to(DEVICE)\n",
    "            solvent_adj_ACE = solvent_adj_ACE.to(DEVICE)\n",
    "            solvent_adj_NMF = solvent_adj_NMF.to(DEVICE)\n",
    "            solvent_adj_wat = solvent_adj_wat.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):  # 当requires_grad设置为False时,反向传播时就不会自动求导了，因此大大节约了显存或者说内存。\n",
    "                outputs = net(solute_data_ACE, solvent_data_ACE, solute_adj, solvent_adj_ACE, solute_data_NMF,\n",
    "                              solvent_data_NMF, solvent_adj_NMF, solute_data_wat,\n",
    "                              solvent_data_wat, solvent_adj_wat,smile).squeeze(-1)\n",
    "                loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            total_loss += loss.item() * outputs.size(0)\n",
    "            # if (i_batch % 1000 == 9):\n",
    "            # print(\"outputs=\", outputs)\n",
    "            # print(\"labels=\", labels)\n",
    "            # print(\"loss=\", loss)\n",
    "\n",
    "            running_loss = 0.0\n",
    "        writer.add_scalar('total loss', total_loss / len(train_loader), epoch+current_epoch)\n",
    "        loss_list.append(total_loss / len(train_loader))\n",
    "        PATH1 = \"./check_point/\" + str(epoch+current_epoch) + 'MyLastGCNTest12_net.pth'\n",
    "        torch.save(net.state_dict(), PATH1)\n",
    "\n",
    "        ACE_accuracy, NMF_accuracy, wat_accuracy = val(net, val_loader, solute_adj, solvent_adj_ACE, solvent_adj_NMF, solvent_adj_wat, epoch+current_epoch)\n",
    "\n",
    "        test_model.load_state_dict(torch.load(PATH1))\n",
    "        best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10 = test(test_model, test_loader, solute_adj, solvent_adj_meth,\n",
    "                                                                   PATH1, bestSUMmeth5, bestSUMmeth10, best_PATH5,\n",
    "                                                                   best_PATH10, epoch+current_epoch, ACE_accuracy, NMF_accuracy, wat_accuracy)\n",
    "        print(\"best_PATH5=\", best_PATH5, \"best_PATH10=\", best_PATH10)\n",
    "    print(\"loss_list = \", loss_list)\n",
    "    print('MyLastGCNTest12 Finished Training, lr=', args.lr, \"batchsize=\", args.batchsize)\n",
    "    return best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc15d442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------build_model----------------------------\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "print(\"--------------------------build_model----------------------------\")\n",
    "net, optimizer, criterion, test_model=build_model()\n",
    "dict_solute = get_solute_position(args.data_src_ACE)\n",
    "dict_solvent_NMF = get_solvent_position(args.data_src_NMF, \"NMF\")\n",
    "dict_solvent_ACE = get_solvent_position(args.data_src_ACE, \"ACE\")\n",
    "dict_solvent_wat = get_solvent_position(args.data_src_wat, \"wat\")\n",
    "dict_solvent_meth = get_solvent_position(args.data_src_meth, \"meth\")\n",
    "solute_adj = get_solute_adj()\n",
    "solute_adj = torch.tensor(solute_adj).T\n",
    "solvent_adj_NMF = get_solvent_adj(\"NMF\", 12150)\n",
    "solvent_adj_NMF = torch.tensor(solvent_adj_NMF).T\n",
    "solvent_adj_ACE = get_solvent_adj(\"ACE\", 8940)\n",
    "solvent_adj_ACE = torch.tensor(solvent_adj_ACE).T\n",
    "solvent_adj_wat = get_solvent_adj(\"wat\", 14784)\n",
    "solvent_adj_wat = torch.tensor(solvent_adj_wat).T\n",
    "solvent_adj_meth = get_solvent_adj(\"meth\", 16335)\n",
    "solvent_adj_meth = torch.tensor(solvent_adj_meth).T\n",
    "meth_atom_to_feature = np.load(\"./meth_atom_to_feature.npy\", allow_pickle=True).item()\n",
    "wat_atom_to_feature = np.load(\"./wat_atom_to_feature.npy\", allow_pickle=True).item()\n",
    "NMF_atom_to_feature = np.load(\"./NMF_atom_to_feature.npy\", allow_pickle=True).item()\n",
    "ACE_atom_to_feature = np.load(\"./ACE_atom_to_feature.npy\", allow_pickle=True).item()\n",
    "solute_addtional_feature = np.load(\"./solute_atom_to_feature.npy\", allow_pickle=True).item()\n",
    "smile = torch.tensor(np.load(\"./smile.npy\", allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23278f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOAD(train_lable_index, val_lable_index, test_list, best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10, current_epoch):\n",
    "    train_loader = load_data(args.data_src_ACE, args.batchsize, \"train\", args.data_src_NMF, train_lable_index, args.data_src_wat)#加载训练用的ACE+NMF+Water\n",
    "    val_loader = load_data(args.data_src_ACE, args.batchsize, \"val\", args.data_src_NMF, val_lable_index, args.data_src_wat) #加载测试用的ACE+NMF+Water\n",
    "    test_loader = load_test_data(args.batchsize, \"test\",test_list, args.data_src_meth) #加载meth\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e48715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRAIN(net, optimizer, criterion, test_model,train_loader, solute_adj, solvent_adj_ACE, solvent_adj_NMF, solvent_adj_wat, val_loader, solvent_adj_meth, test_loader,best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10, current_epoch):\n",
    "    best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10 = train(net, optimizer, criterion, test_model,train_loader, solute_adj, solvent_adj_ACE, solvent_adj_NMF, solvent_adj_wat, val_loader, solvent_adj_meth, test_loader,best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10, current_epoch)\n",
    "    return best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af5d95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 100000):\n",
    "    data_list.append(i)\n",
    "train_lable_index, val_lable_index = train_test_split(data_list, train_size=0.72, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "best_PATH5 = \"\"\n",
    "best_PATH10 = \"\"\n",
    "bestSUMmeth5 = 0\n",
    "bestSUMmeth10 = 0\n",
    "print(\"current_test_list===========================================\", i* 10000)\n",
    "temp_train_lable_index = train_lable_index[i*8:(i+1)*8]\n",
    "temp_val_lable_index = val_lable_index[i * 4: (i + 1) * 4]\n",
    "test_list = temp_train_lable_index + temp_val_lable_index\n",
    "train_loader, val_loader, test_loader = LOAD(temp_train_lable_index, temp_val_lable_index, test_list, best_PATH5, best_PATH10,bestSUMmeth5, bestSUMmeth10, i * args.epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df0808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10 = TRAIN(net, optimizer, criterion, test_model, train_loader, solute_adj, solvent_adj_ACE, solvent_adj_NMF, solvent_adj_wat, val_loader, solvent_adj_meth, test_loader, best_PATH5, best_PATH10, bestSUMmeth5, bestSUMmeth10, i * args.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446be1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f957d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llq] *",
   "language": "python",
   "name": "conda-env-llq-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
